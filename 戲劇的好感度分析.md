
# 戲劇的好感度分析

### 此檔案主要是利用PTT韓劇版的留言，進行近三個月韓劇的好感度分析

## 1. 匯入需要的套件及讀取自PTT韓劇版上爬下來的json檔


```python
import json

with open("KoreaDrama-2055-2060.json",'r', encoding='utf-8') as f1:
    ptt_kor1 = json.load(f1)
with open("KoreaDrama-2061-2065.json",'r', encoding='utf-8') as f2:
    ptt_kor2 = json.load(f2)
with open("KoreaDrama-2066-2070.json",'r', encoding='utf-8') as f3:
    ptt_kor3 = json.load(f3)
with open("KoreaDrama-2071-2075.json",'r', encoding='utf-8') as f4:
    ptt_kor4 = json.load(f4)
with open("KoreaDrama-2076-2080.json",'r', encoding='utf-8') as f5:
    ptt_kor5 = json.load(f5)
with open("KoreaDrama-2081-2087.json",'r', encoding='utf-8') as f6:
    ptt_kor6 = json.load(f6)
```


```python
dic_KR=dict(articles= ptt_kor1['articles']+ptt_kor2['articles']+ptt_kor3['articles']+ptt_kor4['articles']+\
            ptt_kor5['articles']+ptt_kor6['articles'])
```


```python
from collections import Counter
from wordcloud import WordCloud
from matplotlib import pyplot as plt
import pandas as pd
import jieba
import matplotlib.pyplot as plt
import operator 
```

## 2. 將json檔轉為DataFrame


```python
#在ＰＴＴ留言中，標題如有「ＬＩＶＥ」、「心得」或「閒聊」者，有較高的可能在探討戲劇內容，故只抓取包括這三個標題的留言

message_list=[]
article_title_list=[]
for i in dic_KR['articles']:
    if 'LIVE' in i['article_title'] or '心得' in i['article_title'] or '閒聊' in i['article_title']:
        article_title_list.append(i['article_title'])
        message_list.append(i['messages'])
```


```python
from snownlp import SnowNLP

message_all_list=[]
sentiment_all_list=[]

for i in message_list:
    message_info_list=[]
    sentiment_info_list=[]
    for j in i:
        if j['push_content']=='':
            pass
        else:
            message_info_list.append(j['push_content'])
            s=SnowNLP(j['push_content'])
            sentiment_info_list.append(s.sentiments)
            
    message_all_list.append(message_info_list)
    sentiment_all_list.append(sentiment_info_list)
```


```python
tbl={
    "article_title":article_title_list,
    "messge":message_all_list,
    "sentiment":sentiment_all_list
}

df_kor_sentiment=pd.DataFrame(tbl)
df_kor_sentiment.to_csv('df_kor_sentiment.csv', encoding='utf-8')
df_kor_sentiment.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_title</th>
      <th>messge</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>[推一個...小迷糊是我永遠都不敢再看一次的角色, 結局有如利刃般的刺傷所有人的心..., ...</td>
      <td>[0.1182726810403203, 0.661095430613869, 0.1264...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[閒聊] 因為張基龍，久違的心動</td>
      <td>[童星最大的問題大多數是長不高…目前童星出身的演技都很, 好，但是男生幾乎都長不高，最高大概...</td>
      <td>[0.08567608189587561, 0.9722160622727724, 0.41...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[LIVE] tvN 想停止的瞬間：About Time EP5</td>
      <td>[怕大家之後搜尋還是會搜關鍵字 瞬間 所以之後會把前幾, 集標題也補上喔, 推推～, 推, ...</td>
      <td>[0.03099128327226719, 0.012793598422390695, 0....</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[LIVE] 檢法男女 EP13、EP14</td>
      <td>[推, 推!, 推白法醫,但我的心已給俊赫, h大我了解 你去吧XDD，我反而默默被白範圈走...</td>
      <td>[0.36842105263157865, 0.36842105263157865, 0.2...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[LIVE] SBS 油膩的Melo EP17~18</td>
      <td>[推, 赫哥要拼命了..., 這種演員組合拿到這種收視率編導真的是不應該, 其實我覺得這算好...</td>
      <td>[0.36842105263157865, 0.7509583516892715, 0.00...</td>
    </tr>
  </tbody>
</table>
</div>



## 3.利用snownlp進行好感度評估

### 3.1利用snownlp計算好感度


```python
from snownlp import SnowNLP

article_title_together=[]
message_all_list_together=[]
sentiment_all_list_together=[]


for k in range(len(message_list)):
    for l in range(len(message_list[k])):
        if message_list[k][l]['push_content']=='':
            pass
        else:
            message_all_list_together.append(message_list[k][l]['push_content'])
            s=SnowNLP(message_list[k][l]['push_content'])
            sentiment_all_list_together.append(s.sentiments)
            article_title_together.append(article_title_list[k])
```


```python
tbl_together={
    "article_title":article_title_together,
    "messge":message_all_list_together,
    "sentiment":sentiment_all_list_together
}

df_kor_sentiment_together=pd.DataFrame(tbl_together)
```


```python
def add_int(row):
    if pd.notnull(row['article_title']):
        row['int'] = 1
    else:
        row['int'] = 0
    return row
df_kor_sentiment_together = df_kor_sentiment_together.apply(add_int, axis=1)
```


```python
df_kor_sentiment_together.to_csv('df_kor_sentiment_together.csv', encoding='utf-8')
df_kor_sentiment_together.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_title</th>
      <th>messge</th>
      <th>sentiment</th>
      <th>int</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推一個...小迷糊是我永遠都不敢再看一次的角色</td>
      <td>0.118273</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>結局有如利刃般的刺傷所有人的心...</td>
      <td>0.661095</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推推!!</td>
      <td>0.126485</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>小迷糊 QQ</td>
      <td>0.729618</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>出獄後第一眼該想看到的是親情和愛情但換來的卻是寂</td>
      <td>0.977694</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



### 3.2.利用結巴搭配韓劇劇名詞庫，對留言標題進行斷詞


```python
article_title_list=df_kor_sentiment_together['article_title'].tolist()
article_title_list[0:10]
```




    ['[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending',
     '[心得] 機智的牢房生活-小迷糊的Happen ending']




```python
DramaName=pd.read_csv('userdict.csv', encoding='utf-8')
DramaName_list=DramaName['dramaName'].tolist()
DramaName_list[0:10]
```




    ['1006的房客',
     '1006',
     '16個夏天',
     '1989一念間',
     '700歲旅程',
     'A咖的路',
     'High 5 制霸青春',
     'High5 ',
     '制霸青春',
     'HIStory']




```python
jieba.load_userdict("userdict.txt")
with open('stops.txt', 'r', encoding='utf8') as f:
    stops = f.read().split('\n')

stops.append('\n')
stops.append('\n\n')
```

    Building prefix dict from the default dictionary ...
    Loading model from cache C:\Users\mintz\AppData\Local\Temp\jieba.cache
    Loading model cost 1.082 seconds.
    Prefix dict has been built succesfully.
    


```python
info_all=[]
terms_list=[]

for articleTitle in article_title_list:

    terms = [t for t in jieba.cut_for_search(articleTitle) if t not in stops]
    terms_list.append(terms)
        
    
for term in terms_list:
    title_list=[]
    for i in term:
        if i in DramaName_list:
            title_list.append(i)
    if len(title_list)==0:
        info_all.append('無')
    if len(title_list)>0:
        info_all.append(title_list[0])
```


```python
df_kor_sentiment_together['title']=info_all
df_kor_sentiment_together.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_title</th>
      <th>messge</th>
      <th>sentiment</th>
      <th>int</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推一個...小迷糊是我永遠都不敢再看一次的角色</td>
      <td>0.118273</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>結局有如利刃般的刺傷所有人的心...</td>
      <td>0.661095</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推推!!</td>
      <td>0.126485</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>小迷糊 QQ</td>
      <td>0.729618</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>出獄後第一眼該想看到的是親情和愛情但換來的卻是寂</td>
      <td>0.977694</td>
      <td>1</td>
      <td>無</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_kor_sentiment_together_withTitle=df_kor_sentiment_together.replace(['武法律師', '油膩的', '金秘書', '你的管家', 'Sunshine', 'Mr.Sunshine', '一起吃飯吧', '江南美人', 'Signal', 'abouttime'], \
               ['無法律師', '油膩的Melo', '金秘書為何那樣', '妳的管家','陽光先生', '陽光先生', '一起吃飯吧3', '我的ID是江南美人', '信號', '想停止的瞬間'])
```


```python
df_kor_sentiment_together_withTitle.to_csv('df_kor_sentiment_together_withTitle.csv', encoding='utf-8')
df_kor_sentiment_together_withTitle.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_title</th>
      <th>messge</th>
      <th>sentiment</th>
      <th>int</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推一個...小迷糊是我永遠都不敢再看一次的角色</td>
      <td>0.118273</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>結局有如利刃般的刺傷所有人的心...</td>
      <td>0.661095</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>推推!!</td>
      <td>0.126485</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>小迷糊 QQ</td>
      <td>0.729618</td>
      <td>1</td>
      <td>無</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[心得] 機智的牢房生活-小迷糊的Happen ending</td>
      <td>出獄後第一眼該想看到的是親情和愛情但換來的卻是寂</td>
      <td>0.977694</td>
      <td>1</td>
      <td>無</td>
    </tr>
  </tbody>
</table>
</div>



### 3.3. 整理可判斷出戲劇劇名的留言，並且計算平均好感度及留言次數


```python
df_kor_sentiment_together_withTitle2=df_kor_sentiment_together_withTitle[df_kor_sentiment_together_withTitle['title']!='無']
df_kor_sentiment_r=df_kor_sentiment_together_withTitle2.groupby(['title']).mean().sort_values('sentiment', ascending=False)
df_kor_sentiment_r2=df_kor_sentiment_r.reset_index()
df_kor_sentiment_r2.to_csv('df_kor_sentiment_r.csv', encoding='utf-8')
df_kor_sentiment_r_count=df_kor_sentiment_together_withTitle2.groupby(['title']).sum()
df_kor_sentiment_r_count2=df_kor_sentiment_r_count.reset_index()
df_kor_sentiment_r3=pd.merge(df_kor_sentiment_r2, df_kor_sentiment_r_count2, how='left', on='title')
df_kor_sentiment_r3.iloc[:,[0,1,4]]
df_kor_sentiment_r4=df_kor_sentiment_r3.rename(columns={'sentiment_x': 'sentiment', 'int_y': 'all_count'})
df_kor_sentiment_r5=df_kor_sentiment_r4.iloc[:,[0,1,4]]
df_kor_sentiment_r5.to_csv('df_kor_sentiment_r.csv', encoding='utf-8')
df_kor_sentiment_r5.head()
# all_count為總留言數，sentiment為snownlp計算的平均好感度
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>sentiment</th>
      <th>all_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>魔女的法庭</td>
      <td>0.677619</td>
      <td>40</td>
    </tr>
    <tr>
      <th>1</th>
      <td>復仇筆記</td>
      <td>0.625747</td>
      <td>99</td>
    </tr>
    <tr>
      <th>2</th>
      <td>奇蹟</td>
      <td>0.607759</td>
      <td>38</td>
    </tr>
    <tr>
      <th>3</th>
      <td>善良的男人</td>
      <td>0.599300</td>
      <td>71</td>
    </tr>
    <tr>
      <th>4</th>
      <td>評價女王</td>
      <td>0.599226</td>
      <td>62</td>
    </tr>
  </tbody>
</table>
</div>



## 4.建構情感分類模型進行好感度評估

### 4.1 讀入情感詞典


```python
import pandas as pd

negdict = [] #消極情感词典
posdict = [] #積極情感词典
nodict = [] #否定词词典
plusdict = [] #程度副词词典
sl = pd.read_csv('neg_t.txt', header=None, encoding='utf-8')
for i in range(len(sl[0])):
    negdict.append(sl[0][i])
sl = pd.read_csv('pos_t.txt', header=None, encoding='utf-8')
for i in range(len(sl[0])):
    posdict.append(sl[0][i])
sl = pd.read_csv('no_t.txt', header=None, encoding='utf-8')
for i in range(len(sl[0])):
    nodict.append(sl[0][i])
sl = pd.read_csv('plus_t.txt', header=None, encoding='utf-8')
for i in range(len(sl[0])):
    plusdict.append(sl[0][i])
```

### 4.2 建立算法規則


```python
import jieba

def predict(s, negdict, posdict, nodict, plusdict):
    p = 0
    sd = list(jieba.cut(s))
    for i in range(len(sd)):
        if sd[i] in negdict:
            if i>0 and sd[i-1] in nodict:
                p = p + 1
            elif i>0 and sd[i-1] in plusdict:
                p = p - 2
            else: p = p - 1
        elif sd[i] in posdict:
            if i>0 and sd[i-1] in nodict and sd[i-2] in plusdict:
                p = p-2
            elif i>0 and sd[i-1] in negdict and sd[i-2] in plusdict:
                p = p-2
            elif i>0 and sd[i-1] in nodict:
                p = p - 1
            elif i>0 and sd[i-1] in plusdict:
                p = p + 2
            elif i>0 and sd[i-1] in negdict:
                p = p - 1
            elif i<len(sd)-1 and sd[i+1] in negdict:
                p = p - 1
            else: p = p + 1
        elif sd[i] in nodict:
            p = p
    return p
```

### 4.3 利用情感詞典，搭配算法規則，計算好感度


```python
df_kor_sentiment_together_withTitle=pd.read_csv('df_kor_sentiment_together_withTitle.csv', encoding='utf-8')
df_kor_sentiment_together_withTitle1=df_kor_sentiment_together_withTitle[df_kor_sentiment_together_withTitle['title']!='無']
```


```python
s=df_kor_sentiment_together_withTitle1['messge'].tolist()

sentiment_kor_countByMyself=[]

for i in s:
    p_result=predict(i, negdict, posdict, nodict, plusdict)
    sentiment_kor_countByMyself.append(p_result)
```


```python
df_kor_sentiment_together_withTitle1['sentiment_countByMyself']=sentiment_kor_countByMyself
df_kor_sentiment_together_withTitle1.to_csv('df_kor_sentiment_countBymyself_withTitle.csv', encoding='utf-8')
df_kor_sentiment_r=df_kor_sentiment_together_withTitle1.groupby(['title']).sum().sort_values('sentiment_countByMyself', ascending=False)
df_kor_sentiment_r2=df_kor_sentiment_r.reset_index()
df_kor_sentiment_r2.to_csv('df_kor_sentiment_countBymyself_r.csv', encoding='utf-8')
df_kor_sentiment_r2a=df_kor_sentiment_r2.iloc[:, [0,4,3]].rename(columns={'int': 'all_count'})
df_kor_sentiment_r3=df_kor_sentiment_together_withTitle1.groupby(['title']).mean().sort_values('sentiment', ascending=False)
df_kor_sentiment_r4=df_kor_sentiment_r3.reset_index()
df_kor_sentiment_r4a=df_kor_sentiment_r4.iloc[:,[0,2]]
df_kor_sentiment_snownlp_countByMyself=pd.merge(df_kor_sentiment_r2a, df_kor_sentiment_r4a, how='left', on='title')
df_kor_sentiment_snownlp_countByMyself2=df_kor_sentiment_snownlp_countByMyself.iloc[:,[0,2,1,3]]
df_kor_sentiment_snownlp_countByMyself2.to_csv('df_kor_sentiment_snownlp_countByMyself.csv', encoding='utf-8')
df_kor_sentiment_snownlp_countByMyself2.head()
```

    C:\Anaconda3\lib\site-packages\ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      """Entry point for launching an IPython kernel.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>all_count</th>
      <th>sentiment_countByMyself</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>金秘書為何那樣</td>
      <td>12894</td>
      <td>5676</td>
      <td>0.511544</td>
    </tr>
    <tr>
      <th>1</th>
      <td>雖然30但仍17</td>
      <td>2156</td>
      <td>1199</td>
      <td>0.505104</td>
    </tr>
    <tr>
      <th>2</th>
      <td>我的ID是江南美人</td>
      <td>1569</td>
      <td>985</td>
      <td>0.524160</td>
    </tr>
    <tr>
      <th>3</th>
      <td>漢摩拉比小姐</td>
      <td>4482</td>
      <td>736</td>
      <td>0.462798</td>
    </tr>
    <tr>
      <th>4</th>
      <td>一起吃飯吧3</td>
      <td>1463</td>
      <td>574</td>
      <td>0.476000</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_kor_sentiment_r5=df_kor_sentiment_together_withTitle1.groupby(['title']).mean().sort_values('sentiment_countByMyself', ascending=False)
df_kor_sentiment_r6=df_kor_sentiment_r5.reset_index()
df_kor_sentiment_r6a=df_kor_sentiment_r6.iloc[:, [0,4,3]]
df_kor_sentiment_r_count=df_kor_sentiment_together_withTitle1.groupby(['title']).sum()
df_kor_sentiment_r_count2=df_kor_sentiment_r_count.reset_index()
df_kor_sentiment_r6b=pd.merge(df_kor_sentiment_r6a, df_kor_sentiment_r_count2, how='left', on='title')
df_kor_sentiment_r6c=df_kor_sentiment_r6b.iloc[:,[0,5,1]].rename(columns={'int_y': 'all_count', 'sentiment_countByMyself_x':'sentiment_countByMyself_mean'})
df_kor_sentiment_r6c.to_csv('df_kor_sentiment_countBymyself_mean_r.csv', encoding='utf-8')
df_kor_sentiment_snownlp_countByMyself_sum_mean=pd.merge(df_kor_sentiment_snownlp_countByMyself2, df_kor_sentiment_r6c, how='left', on='title')
df_kor_sentiment_snownlp_countByMyself_sum_mean2=df_kor_sentiment_snownlp_countByMyself_sum_mean.iloc[:,[0,1,5,3]].rename(columns={'all_count_x': 'all_count'})
df_kor_sentiment_all=df_kor_sentiment_snownlp_countByMyself_sum_mean2[df_kor_sentiment_snownlp_countByMyself_sum_mean2['all_count']>150].sort_values('sentiment_countByMyself_mean', ascending=False).reset_index(drop=True)
df_kor_sentiment_all.head()

# all_count為總留言數，sentiment_countByMyself_mean為本模型計算的平均好感度，sentiment為snownlp計算的平均好感度
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>all_count</th>
      <th>sentiment_countByMyself_mean</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>我的ID是江南美人</td>
      <td>1569</td>
      <td>0.627788</td>
      <td>0.524160</td>
    </tr>
    <tr>
      <th>1</th>
      <td>我的大叔</td>
      <td>798</td>
      <td>0.614035</td>
      <td>0.530610</td>
    </tr>
    <tr>
      <th>2</th>
      <td>秘密</td>
      <td>244</td>
      <td>0.573770</td>
      <td>0.528558</td>
    </tr>
    <tr>
      <th>3</th>
      <td>雖然30但仍17</td>
      <td>2156</td>
      <td>0.556122</td>
      <td>0.505104</td>
    </tr>
    <tr>
      <th>4</th>
      <td>妳的管家</td>
      <td>333</td>
      <td>0.483483</td>
      <td>0.533742</td>
    </tr>
  </tbody>
</table>
</div>


